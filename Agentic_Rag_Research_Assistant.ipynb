{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N31qb6EUGqzx",
        "outputId": "33a2f385-a1d2-4607-9783-96394158b8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fpdf, sgmllib3k\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=97a09906acf60473f4c4677abf66c4c611532a7240cc6df9837fd99d3619d37c\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=0279225a66f73c869117ef38bb7d64500223e15f2d51f3f37420bdd28f05577c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built fpdf sgmllib3k\n",
            "Installing collected packages: sgmllib3k, fpdf, feedparser, arxiv\n",
            "Successfully installed arxiv-2.2.0 feedparser-6.0.11 fpdf-1.7.2 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arxiv fpdf requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENROUTER_API_KEY = \"ENTER-YOUR-OPENROUTER-API-KEY\"\n",
        "OPENROUTER_MODEL = \"qwen/qwen3-coder:free\""
      ],
      "metadata": {
        "id": "LiSCV2PxHxgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "\n",
        "def search_arxiv_papers(query, max_results=5):\n",
        "    search = arxiv.Search(\n",
        "        query=query,\n",
        "        max_results=max_results,\n",
        "        sort_by=arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "    papers = []\n",
        "    for result in search.results():\n",
        "        papers.append({\n",
        "            \"title\": result.title,\n",
        "            \"summary\": result.summary,\n",
        "            \"pdf_url\": result.pdf_url\n",
        "        })\n",
        "    return papers"
      ],
      "metadata": {
        "id": "pJq7nnqXH0Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def summarize_with_openrouter(text):\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": OPENROUTER_MODEL,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful academic research assistant. Summarize academic abstracts clearly and concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following abstract:\\n\\n{text}\"}\n",
        "        ],\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 1024\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        return f\"‚ùå Error {response.status_code}: {response.text}\""
      ],
      "metadata": {
        "id": "KVMu4MERH3If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_literature_review(topic, papers):\n",
        "    report = f\"# Literature Review on: {topic}\\n\\n\"\n",
        "    for i, paper in enumerate(papers):\n",
        "        title = paper['title']\n",
        "        print(f\"üîÑ Summarizing paper {i+1}: {title}\")\n",
        "        summary = summarize_with_openrouter(paper['summary'])\n",
        "        link = paper['pdf_url']\n",
        "        report += f\"### {i+1}. {title}\\n\\n\"\n",
        "        report += f\"**Summary:** {summary}\\n\\n\"\n",
        "        report += f\"**PDF Link:** [View Paper]({link})\\n\\n---\\n\\n\"\n",
        "    report += \"*Generated by Autonomous Research Assistant using OpenRouter AI.*\"\n",
        "    return report"
      ],
      "metadata": {
        "id": "wFpT2ce7H4Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "def save_report_as_pdf(report_text, filename=\"literature_review.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    for line in report_text.split('\\n'):\n",
        "        pdf.multi_cell(0, 10, line)\n",
        "    pdf.output(filename)\n",
        "    print(f\"‚úÖ PDF saved: {filename}\")"
      ],
      "metadata": {
        "id": "Q1MeJa9WH6MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "research_topic = \"Multimodal AI\"\n",
        "papers = search_arxiv_papers(research_topic, max_results=5)\n",
        "report_text = generate_literature_review(research_topic, papers)\n",
        "save_report_as_pdf(report_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ5B3Y9TH8T3",
        "outputId": "8f5db2fc-3822-4c31-d38d-f7a20f348c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-4176154379.py:10: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Summarizing paper 1: Toward AI-driven Multimodal Interfaces for Industrial CAD Modeling\n",
            "üîÑ Summarizing paper 2: Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications\n",
            "üîÑ Summarizing paper 3: Multimodal foundation models are better simulators of the human brain\n",
            "üîÑ Summarizing paper 4: Multimodal Conversational AI: A Survey of Datasets and Approaches\n",
            "üîÑ Summarizing paper 5: Towards a Multimodal Document-grounded Conversational AI System for Education\n",
            "‚úÖ PDF saved: literature_review.pdf\n"
          ]
        }
      ]
    }
  ]
}